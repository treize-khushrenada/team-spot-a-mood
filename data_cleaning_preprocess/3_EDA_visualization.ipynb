{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "# import pycaret\n",
    "\n",
    "from bertopic import BERTopic\n",
    "# from yellowbrick.cluster import SilhouetteVisualizer\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0313, -0.0150, -0.0006,  ...,  0.0447, -0.0176, -0.0370],\n",
       "         [-0.0168,  0.0209, -0.0274,  ..., -0.0035, -0.0133,  0.0259],\n",
       "         [ 0.0151,  0.0208, -0.0065,  ...,  0.0728, -0.0307, -0.0515],\n",
       "         ...,\n",
       "         [-0.0303, -0.0342, -0.0244,  ...,  0.0129, -0.0141, -0.0380],\n",
       "         [-0.0509, -0.0455, -0.0220,  ...,  0.0224,  0.0002, -0.0097],\n",
       "         [-0.0075, -0.0047, -0.0154,  ...,  0.0279,  0.0229, -0.0375]]),\n",
       " array([39838, 39838, 39838, ..., 17009, 17009, 17009]),\n",
       " array(['County Jail Blues Lyrics[Verse]', 'They picked me up',\n",
       "        'Put me in the county jail', ...,\n",
       "        'If you wanted to spend some time with me',\n",
       "        'You should have respected my virtue',\n",
       "        \"You know what I'm sayin'You might also likeEmbed\"], dtype='<U1837'),\n",
       "                               artist                        title  \\\n",
       " 0                     A Few Good Men                       Tonite   \n",
       " 1                     A Few Good Men                 Have I Never   \n",
       " 2                     A Few Good Men   Don't Cry (Behind My Back)   \n",
       " 3                A Flock Of Seagulls     Modern Love Is Automatic   \n",
       " 4                A Flock Of Seagulls                      Windows   \n",
       " ...                              ...                          ...   \n",
       " 90717  Merle Haggard & The Strangers  The Seashores Of Old Mexico   \n",
       " 90718  Merle Haggard & The Strangers     You'll Always Be Special   \n",
       " 90719  Merle Haggard & The Strangers           Always Wanting You   \n",
       " 90720  Merle Haggard & The Strangers  A Man's Gotta Give Up A Lot   \n",
       " 90721  Merle Haggard & The Strangers       It's All In The Movies   \n",
       " \n",
       "        danceability  energy   key  loudness  mode  speechiness  acousticness  \\\n",
       " 0             0.615   0.673   5.0    -8.501   0.0       0.1150        0.0429   \n",
       " 1             0.717   0.377   4.0    -8.680   1.0       0.0288        0.2820   \n",
       " 2             0.774   0.691  10.0    -6.815   1.0       0.0403        0.0827   \n",
       " 3             0.323   0.821   7.0    -6.245   1.0       0.1090        0.0444   \n",
       " 4             0.629   0.683   0.0   -12.306   1.0       0.0324        0.1200   \n",
       " ...             ...     ...   ...       ...   ...          ...           ...   \n",
       " 90717         0.611   0.348  10.0   -11.815   1.0       0.0362        0.5100   \n",
       " 90718         0.312   0.243   8.0   -13.515   1.0       0.0303        0.7910   \n",
       " 90719         0.585   0.309   7.0   -13.670   1.0       0.0245        0.8580   \n",
       " 90720         0.738   0.529   5.0   -11.433   1.0       0.0446        0.7270   \n",
       " 90721         0.638   0.423   9.0   -12.427   1.0       0.0375        0.8350   \n",
       " \n",
       "        instrumentalness  ...  valence    tempo  duration  time_signature  \\\n",
       " 0              0.000000  ...    0.831  178.124  254360.0             4.0   \n",
       " 1              0.000000  ...    0.161  120.036  336533.0             4.0   \n",
       " 2              0.000000  ...    0.850  134.050  308267.0             4.0   \n",
       " 3              0.979000  ...    0.192  162.700  230200.0             4.0   \n",
       " 4              0.480000  ...    0.708  150.083  210827.0             4.0   \n",
       " ...                 ...  ...      ...      ...       ...             ...   \n",
       " 90717          0.000252  ...    0.689   81.310  225120.0             3.0   \n",
       " 90718          0.000038  ...    0.360   77.160  154987.0             3.0   \n",
       " 90719          0.267000  ...    0.520   96.106  188760.0             4.0   \n",
       " 90720          0.000034  ...    0.877  139.217  154973.0             4.0   \n",
       " 90721          0.000862  ...    0.567   89.061  198080.0             4.0   \n",
       " \n",
       "                                                   lyrics  genius_id  \\\n",
       " 0      Tonite LyricsYou know I really want to love yo...  1382268.0   \n",
       " 1      Have I Never LyricsHave I never told you I lov...  1187594.0   \n",
       " 2      Don’t Cry (Behind My Back) LyricsDon't cry, do...   897142.0   \n",
       " 3      Modern Love Is Automatic LyricsShe's an automa...   969269.0   \n",
       " 4      Windows LyricsMy phobia has got me and I dare ...  1510901.0   \n",
       " ...                                                  ...        ...   \n",
       " 90717  Willie Nelson Cleanup Page LyricsTracking Shee...  4523569.0   \n",
       " 90718  MusiCares Person of the Year Speech LyricsI'm ...   701981.0   \n",
       " 90719  Little Dorrit (Chap 1.1) LyricsSun and Shadow\\...   159929.0   \n",
       " 90720  2016 White House Correspondents’ Dinner Speech...  2466391.0   \n",
       " 90721  Songs That Reference Drugs LyricsIn alphabetic...  1453509.0   \n",
       " \n",
       "                                               annotation  \\\n",
       " 0                                                     []   \n",
       " 1                                                     []   \n",
       " 2                                                     []   \n",
       " 3                                                     []   \n",
       " 4                                                     []   \n",
       " ...                                                  ...   \n",
       " 90717  [('Music from Songwriter (1984) (with Kris Kri...   \n",
       " 90718  [('Merle Haggard didn’t even think much of my ...   \n",
       " 90719  [('‘How goes the world this forenoon, gentleme...   \n",
       " 90720  [('I think Fox News secretly likes Beyoncé, th...   \n",
       " 90721  [('Jim Stafford', [[\"Try a little and before y...   \n",
       " \n",
       "                                              lyrics_list   line_len  song_len  \n",
       " 0      ['Tonite LyricsYou know I really want to love ...   6.666667        66  \n",
       " 1      ['Have I Never LyricsHave I never told you I l...   8.196078        51  \n",
       " 2      [\"Don’t Cry (Behind My Back) LyricsDon't cry, ...   5.371429        70  \n",
       " 3      [\"Modern Love Is Automatic LyricsShe's an auto...   3.147059        34  \n",
       " 4      ['Windows LyricsMy phobia has got me and I dar...   8.758621        29  \n",
       " ...                                                  ...        ...       ...  \n",
       " 90717  ['Willie Nelson Cleanup Page LyricsTracking Sh...   5.173077       208  \n",
       " 90718  [\"MusiCares Person of the Year Speech LyricsI'...  21.456432       241  \n",
       " 90719  ['Little Dorrit (Chap 1.1) LyricsSun and Shado...  24.838565       223  \n",
       " 90720  ['2016 White House Correspondents’ Dinner Spee...  15.821229       179  \n",
       " 90721  ['Songs That Reference Drugs LyricsIn alphabet...   4.709898       293  \n",
       " \n",
       " [90722 rows x 21 columns],\n",
       " 0        Tonite LyricsYou know I really want to love yo...\n",
       " 1        Have I Never LyricsHave I never told you I lov...\n",
       " 2        Don’t Cry (Behind My Back) LyricsDon't cry, do...\n",
       " 3        Modern Love Is Automatic LyricsShe's an automa...\n",
       " 4        Windows LyricsMy phobia has got me and I dare ...\n",
       "                                ...                        \n",
       " 90717    Willie Nelson Cleanup Page LyricsTracking Shee...\n",
       " 90718    MusiCares Person of the Year Speech LyricsI'm ...\n",
       " 90719    Little Dorrit (Chap 1.1) LyricsSun and Shadow\\...\n",
       " 90720    2016 White House Correspondents’ Dinner Speech...\n",
       " 90721    Songs That Reference Drugs LyricsIn alphabetic...\n",
       " Name: lyrics, Length: 90722, dtype: object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform lyrics to vector embedding\n",
    "# get the vector embedding of the sampling 1000 dataset from the 100k songs data >> preprocess_lyrics.ipynb\n",
    "with open('../App/pickle_objects/embeddings_indices.obj', 'rb') as f:\n",
    "    embeddings, arr_song_idx, arr_lyrics_idx = pickle.load(f)\n",
    "\n",
    "with open('../App/pickle_objects/sample_song_lyrics_set.obj', 'rb') as f:\n",
    "    songs_set, lyrics_set = pickle.load(f)\n",
    "embeddings, arr_song_idx, arr_lyrics_idx, songs_set, lyrics_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting songs index to be trained with bertopic\n",
    "songs_idx = sorted(list(set(arr_song_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting songs in the index\n",
    "sample_songs_set = songs_set.loc[songs_set.index.isin(songs_idx)]\n",
    "lyrics = sample_songs_set['lyrics'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\poomk\\OneDrive\\Desktop\\songsdata\\data_cleaning_preprocess\\3_EDA_visualization.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/poomk/OneDrive/Desktop/songsdata/data_cleaning_preprocess/3_EDA_visualization.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m topic_model \u001b[39m=\u001b[39m BERTopic()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/poomk/OneDrive/Desktop/songsdata/data_cleaning_preprocess/3_EDA_visualization.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m topics, probs \u001b[39m=\u001b[39m topic_model\u001b[39m.\u001b[39;49mfit_transform(lyrics)\n",
      "File \u001b[1;32mc:\\Users\\poomk\\miniconda3\\envs\\dataenv\\lib\\site-packages\\bertopic\\_bertopic.py:333\u001b[0m, in \u001b[0;36mBERTopic.fit_transform\u001b[1;34m(self, documents, embeddings, y)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[39mif\u001b[39;00m embeddings \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    331\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_model \u001b[39m=\u001b[39m select_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_model,\n\u001b[0;32m    332\u001b[0m                                           language\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlanguage)\n\u001b[1;32m--> 333\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extract_embeddings(documents\u001b[39m.\u001b[39;49mDocument,\n\u001b[0;32m    334\u001b[0m                                           method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdocument\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    335\u001b[0m                                           verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose)\n\u001b[0;32m    336\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mTransformed documents to Embeddings\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    337\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\poomk\\miniconda3\\envs\\dataenv\\lib\\site-packages\\bertopic\\_bertopic.py:2244\u001b[0m, in \u001b[0;36mBERTopic._extract_embeddings\u001b[1;34m(self, documents, method, verbose)\u001b[0m\n\u001b[0;32m   2242\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_model\u001b[39m.\u001b[39membed_words(documents, verbose)\n\u001b[0;32m   2243\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdocument\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 2244\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding_model\u001b[39m.\u001b[39;49membed_documents(documents, verbose)\n\u001b[0;32m   2245\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2246\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mWrong method for extracting document/word embeddings. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2247\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mEither choose \u001b[39m\u001b[39m'\u001b[39m\u001b[39mword\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mdocument\u001b[39m\u001b[39m'\u001b[39m\u001b[39m as the method. \u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\poomk\\miniconda3\\envs\\dataenv\\lib\\site-packages\\bertopic\\backend\\_base.py:69\u001b[0m, in \u001b[0;36mBaseEmbedder.embed_documents\u001b[1;34m(self, document, verbose)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39membed_documents\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[0;32m     56\u001b[0m                     document: List[\u001b[39mstr\u001b[39m],\n\u001b[0;32m     57\u001b[0m                     verbose: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m     58\u001b[0m     \u001b[39m\"\"\" Embed a list of n words into an n-dimensional\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[39m    matrix of embeddings\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[39m        that each have an embeddings size of `m`\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed(document, verbose)\n",
      "File \u001b[1;32mc:\\Users\\poomk\\miniconda3\\envs\\dataenv\\lib\\site-packages\\bertopic\\backend\\_sentencetransformers.py:63\u001b[0m, in \u001b[0;36mSentenceTransformerBackend.embed\u001b[1;34m(self, documents, verbose)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39membed\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[0;32m     50\u001b[0m           documents: List[\u001b[39mstr\u001b[39m],\n\u001b[0;32m     51\u001b[0m           verbose: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m     52\u001b[0m     \u001b[39m\"\"\" Embed a list of n documents/words into an n-dimensional\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[39m    matrix of embeddings\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39m        that each have an embeddings size of `m`\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding_model\u001b[39m.\u001b[39;49mencode(documents, show_progress_bar\u001b[39m=\u001b[39;49mverbose)\n\u001b[0;32m     64\u001b[0m     \u001b[39mreturn\u001b[39;00m embeddings\n",
      "File \u001b[1;32mc:\\Users\\poomk\\miniconda3\\envs\\dataenv\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:187\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[1;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[0;32m    185\u001b[0m     all_embeddings \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(all_embeddings)\n\u001b[0;32m    186\u001b[0m \u001b[39melif\u001b[39;00m convert_to_numpy:\n\u001b[1;32m--> 187\u001b[0m     all_embeddings \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray([emb\u001b[39m.\u001b[39mnumpy() \u001b[39mfor\u001b[39;00m emb \u001b[39min\u001b[39;00m all_embeddings])\n\u001b[0;32m    189\u001b[0m \u001b[39mif\u001b[39;00m input_was_string:\n\u001b[0;32m    190\u001b[0m     all_embeddings \u001b[39m=\u001b[39m all_embeddings[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\poomk\\miniconda3\\envs\\dataenv\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:187\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    185\u001b[0m     all_embeddings \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(all_embeddings)\n\u001b[0;32m    186\u001b[0m \u001b[39melif\u001b[39;00m convert_to_numpy:\n\u001b[1;32m--> 187\u001b[0m     all_embeddings \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray([emb\u001b[39m.\u001b[39;49mnumpy() \u001b[39mfor\u001b[39;00m emb \u001b[39min\u001b[39;00m all_embeddings])\n\u001b[0;32m    189\u001b[0m \u001b[39mif\u001b[39;00m input_was_string:\n\u001b[0;32m    190\u001b[0m     all_embeddings \u001b[39m=\u001b[39m all_embeddings[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "topic_model = BERTopic()\n",
    "topics, probs = topic_model.fit_transform(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding cluster using all the features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster visualization with text and valence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "docs = fetch_20newsgroups(subset='all')['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('dataenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "467f60c46b88ea196e8e4e51716c4f14b05141d893e1660e0038b81da854c476"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
