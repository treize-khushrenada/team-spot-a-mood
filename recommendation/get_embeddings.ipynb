{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "# Data manipulation\n",
    "import re\n",
    "import pickle\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "#first time usage: download addtional packages form nltk first:\n",
    "#nltk.download()\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddings_gen(lyrics_set, model_name = \"all-distilroberta-v1\"):\n",
    "    # Create mdoel\n",
    "    model = SentenceTransformer(model_name)\n",
    "    # Create bag of lyrics lines with their corresponding song_ids\n",
    "    l_lyrics_lines =[]\n",
    "    l_song_idx =[]\n",
    "    for idx in lyrics_set.index:\n",
    "        lyrics = lyrics_set[idx]\n",
    "        lyrics_lines = re.split('\\n',lyrics)\n",
    "        # Condition: do not include lyrics lines that are more than 512 tokens\n",
    "        if any(len(word_tokenize(x)) >= 512 for x in lyrics_lines):\n",
    "            continue\n",
    "        l_lyrics_lines.extend(lyrics_lines)\n",
    "        l_song_idx.extend([idx] * len(lyrics_lines))\n",
    "\n",
    "    # For invert indexing //Store related song ids as np array\n",
    "    arr_song_idx = np.array(l_song_idx)\n",
    "    # Store lyrics lines as np array\n",
    "    arr_lyrics_idx = np.array(l_lyrics_lines)\n",
    "\n",
    "    embeddings = model.encode(l_lyrics_lines, convert_to_tensor=True)\n",
    "    \n",
    "    return embeddings, arr_song_idx, arr_lyrics_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE REFER TO preprocessing.ipynb FOR PREPROCESSING STEP\n",
    "with open('../pickle_objects/sample_song_lyrics_set.obj', 'rb') as f:\n",
    "    l_pickle = pickle.load(f)\n",
    "\n",
    "lyrics_set = l_pickle[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, arr_song_idx, arr_lyrics_idx = embeddings_gen(lyrics_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickle_objects/embeddings.obj', 'wb') as f:\n",
    "    pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickle_objects/arr_song_idx.obj', 'wb') as f:\n",
    "    pickle.dump(arr_song_idx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickle_objects/arr_lyrics_idx.obj', 'wb') as f:\n",
    "    pickle.dump(arr_lyrics_idx, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('sam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1e9e221c7a8b896049a5643dbc55f3c8ad76c8b9df1c7f7e9d1ce1ca950a084"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
